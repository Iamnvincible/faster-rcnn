{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caffevgg16(vgg16path):\n",
    "    # the 30th layer of features is relu of conv5_3\n",
    "    model = vgg16(pretrained=False)\n",
    "    caffevgg = t.load(vgg16path)\n",
    "    caffekeys = list(caffevgg.keys())\n",
    "    i = 0\n",
    "    for name, para in model.state_dict().items():\n",
    "        para.copy_(caffevgg[caffekeys[i]])\n",
    "        i += 1\n",
    "    features = list(model.features)[:30]\n",
    "    classifier = model.classifier\n",
    "\n",
    "    classifier = list(classifier)\n",
    "    del classifier[6]\n",
    "    use_drop = True\n",
    "    if not use_drop:\n",
    "        del classifier[5]\n",
    "        del classifier[2]\n",
    "    classifier = nn.Sequential(*classifier)\n",
    "\n",
    "    # freeze top4 conv\n",
    "    for layer in features[:10]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    return nn.Sequential(*features), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature,classifier = caffevgg16('vgg16-00b39a1b.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VOCDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2007 = VOCDetection('./','2007','train',False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(voc2007,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotation': {'folder': ['VOC2007'], 'filename': ['000012.jpg'], 'source': {'database': ['The VOC2007 Database'], 'annotation': ['PASCAL VOC2007'], 'image': ['flickr'], 'flickrid': ['207539885']}, 'owner': {'flickrid': ['KevBow'], 'name': ['?']}, 'size': {'width': ['500'], 'height': ['333'], 'depth': ['3']}, 'segmented': ['0'], 'object': {'name': ['car'], 'pose': ['Rear'], 'truncated': ['0'], 'difficult': ['0'], 'bndbox': {'xmin': ['156'], 'ymin': ['97'], 'xmax': ['351'], 'ymax': ['270']}}}}\n"
     ]
    }
   ],
   "source": [
    "for i,(img,xml) in enumerate(dataloader):\n",
    "    print(xml)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VOCDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class VOCdataloader(DataLoader):\n",
    "    def __init__(self, vocdevkitpath, year, image_set, batch_size=1, shuffle=False, sampler=None,\n",
    "                 batch_sampler=None, num_workers=0, collate_fn=t.utils.data._utils.collate.default_collate,\n",
    "                 pin_memory=False, drop_last=False, timeout=0,\n",
    "                 worker_init_fn=None):\n",
    "        self.dataset = VOCDetection(\n",
    "            vocdevkitpath, year, image_set, False, transform=transforms.ToTensor())\n",
    "        super().__init__(self.dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler, num_workers=num_workers,\n",
    "                         pin_memory=pin_memory, drop_last=drop_last, timeout=timeout, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocdataloader = VOCdataloader('./','2007','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "vocdata = VOCdataloader('./', '2007', 'train')\n",
    "for i, (image, xml) in enumerate(vocdata):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
